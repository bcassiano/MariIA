import sys
import os
import json
import argparse
from typing import Dict, List, Optional, AsyncGenerator
import pandas as pd
import vertexai
from vertexai.generative_models import GenerativeModel, SafetySetting, Tool, FunctionDeclaration, Part, Content
import re
from cachetools import cached, TTLCache

# Adiciona o diret√≥rio raiz ao path para importar m√≥dulos
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '../../')))
from src.database.connector import DatabaseConnector

# Configura√ß√µes Vertex AI
from src.core.config import get_settings
settings = get_settings()

GLOBAL_ENDPOINT = "aiplatform.googleapis.com"

class TelesalesAgent:
    def __init__(self):
        print("DEBUG: Iniciando Vertex AI Agent com Tools...", flush=True)
        try:
            vertexai.init(project=settings.PROJECT_ID, location=settings.LOCATION, api_endpoint=GLOBAL_ENDPOINT)
            
            # --- Defini√ß√£o das Tools (Function Calling) ---
            
            get_customer_history_func = FunctionDeclaration(
                name="get_customer_history_markdown",
                description="Busca hist√≥rico de compras recente de um cliente. Use para entender o padr√£o de compra.",
                parameters={
                    "type": "object",
                    "properties": {
                        "card_code": {"type": "string", "description": "C√≥digo do Cliente (Ex: C00123)"},
                        "limit": {"type": "integer", "description": "N√∫mero m√°ximo de pedidos para retornar (Padr√£o: 10)."}
                    },
                    "required": ["card_code"]
                },
            )

            get_customer_details_func = FunctionDeclaration(
                name="get_customer_details_json_string",
                description="Busca informa√ß√µes de cadastro do cliente (Nome, Endere√ßo, Contato).",
                parameters={
                    "type": "object",
                    "properties": {
                        "card_code": {"type": "string", "description": "C√≥digo do Cliente (Ex: C00123)"}
                    },
                    "required": ["card_code"]
                },
            )

            get_sales_insights_func = FunctionDeclaration(
                name="get_sales_insights_markdown",
                description="Busca insights gerais de vendas e clientes ativos na carteira do vendedor.",
                parameters={
                    "type": "object",
                    "properties": {
                        "days": {"type": "integer", "description": "Dias para an√°lise (Padr√£o: 30)"}
                    }
                },
            )

            run_sales_analysis_query_func = FunctionDeclaration(
                name="run_sales_analysis_query",
                description="Executa uma consulta SQL personalizada para responder perguntas anal√≠ticas complexas sobre vendas (Ex: Rankings, M√©dias, Agrupamentos).",
                parameters={
                    "type": "object",
                    "properties": {
                        "t_sql_query": {"type": "string", "description": "A consulta T-SQL (SELECT apenas) na tabela FAL_IA_Dados_Vendas_Televendas."},
                        "explanation": {"type": "string", "description": "Explica√ß√£o breve do que a query busca."}
                    },
                    "required": ["t_sql_query"]
                },
            )

            get_inactive_customers_func = FunctionDeclaration(
                name="get_inactive_customers_markdown",
                description="Busca clientes INATIVOS (risco de churn) na carteira.",
                parameters={
                    "type": "object",
                    "properties": {
                        "days_without_purchase": {"type": "integer", "description": "Dias sem comprar (Padr√£o: 30)"}
                    }
                },
            )

            get_top_products_func = FunctionDeclaration(
                name="get_top_products",
                description="Busca os produtos mais vendidos (Cat√°logo/Ranking).",
                parameters={
                    "type": "object",
                    "properties": {
                        "days": {"type": "integer", "description": "Per√≠odo de dias (Padr√£o: 90)"}
                    }
                },
            )
            
            get_company_kpis_func = FunctionDeclaration(
                name="get_company_kpis",
                description="Busca KPIs globais da empresa (Faturamento, Totais) para Diretores.",
                parameters={
                    "type": "object",
                    "properties": {
                        "days": {"type": "integer", "description": "Per√≠odo de dias (Padr√£o: 30)"}
                    }
                },
            )
            
            get_top_sellers_func = FunctionDeclaration(
                name="get_top_sellers",
                description="Busca ranking de melhores vendedores.",
                parameters={
                    "type": "object",
                    "properties": {
                        "days": {"type": "integer", "description": "Per√≠odo de dias (Padr√£o: 30)"}
                    }
                },
            )

            # Agrupa as tools
            telesales_tools = Tool(
                function_declarations=[
                    get_customer_history_func,
                    get_customer_details_func,
                    get_sales_insights_func,
                    run_sales_analysis_query_func, # NOVA TOOL
                    get_inactive_customers_func,
                    get_top_products_func,
                    get_company_kpis_func,
                    get_top_sellers_func
                ]
            )

            self.model = GenerativeModel(
                model_name=settings.MODEL_ID,
                system_instruction="""
                Voc√™ √© um Assistente Especialista em Televendas (B2B) da empresa Fant√°stico Alimentos.
                Sua miss√£o √© ajudar vendedores e diretores com dados e insights.
                
                FERRAMENTAS DISPON√çVEIS:
                Voc√™ tem acesso a ferramentas reais para buscar dados do banco de dados (SAP B1).
                
                *** NOVO: AN√ÅLISE AUT√îNOMA DE DADOS (SQL) ***
                Para perguntas complexas onde as ferramentas padr√µes n√£o bastam (ex: "Qual a m√©dia de fardos?", "Quem comprou mais Item X?"), 
                VOC√ä DEVE CRIAR UMA QUERY SQL usando a ferramenta `run_sales_analysis_query`.
                
                ESQUEMA DA TABELA DISPON√çVEL (`FAL_IA_Dados_Vendas_Televendas`):
                - `Data_Emissao` (Date): Data da venda.
                - `Numero_Documento` (Int): N√∫mero do pedido.
                - `SKU` (String): C√≥digo do produto (formato 0005).
                - `Nome_Produto` (String): Nome do item.
                - `Quantidade` (Decimal): Quantidade em Fardos/Unidades.
                - `Valor_Liquido` (Decimal): Valor total do item (R$).
                - `Nome_Cliente` (String): Raz√£o Social.
                - `Codigo_Cliente` (String): CardCode (Ex: C00123).
                - `Vendedor_Atual` (String): Nome do vendedor (Use para filtrar carteira se necess√°rio).
                - `Cidade` (String): Cidade do cliente.
                - `Estado` (String): UF.
                - `Categoria_Produto` (String): Categoria principal (ARROZ, FEIJAO, etc).

                DIRETRIZES GERAIS:
                1. Contexto: Voc√™ fala com vendedores na rua (mobile). Seja BREVE e PR√ÅTICO.
                2. Formata√ß√£o: Use Markdown (negrito, listas) para facilitar a leitura.
                3. Proatividade: Se a an√°lise for complexa, explique o que voc√™ calculou antes de mostrar os dados.
                4. Clientes: Quando falar de um cliente, sempre cite o C√≥digo (CardCode).
                5. SQL Seguro: APENAS SELECT. Nunca tente alterar dados.
                
                Lembre-se: Use `run_sales_analysis_query` sempre que precisar de um ranking, agrupamento ou m√©trica que n√£o exista nas tools prontas.
                """,
                tools=[telesales_tools]
            )
            print("DEBUG: Vertex AI Model + Tools OK.", flush=True)

        except Exception as e:
            print(f"AVISO: Falha ao iniciar Vertex AI ({e}).", flush=True)
            self.model = None
            
        print("DEBUG: Iniciando DatabaseConnector...", flush=True)
        self.db = DatabaseConnector()
        # Cache para perfis de clientes (M√©dia FD de 6 meses) - 24h de TTL
        self.profile_cache = TTLCache(maxsize=2000, ttl=3600 * 24)
        print("DEBUG: Init conclu√≠do.", flush=True)

    def _resolve_vendor_filter(self, vendor_filter: str) -> str:
        """
        Resolve o filtro de vendedor.
        Se receber um ID num√©rico (SlpCode), busca o nome (SlpName) na tabela OSLP.
        Se receber texto, assume que j√° √© o nome.
        """
        if not vendor_filter:
            return None
            
        # Se for num√©rico, tenta resolver o nome
        if str(vendor_filter).isdigit():
            try:
                slp_code = int(vendor_filter)
                # Tenta buscar pelo SlpCode na tabela oficial de vendedores
                query = "SELECT SlpName FROM OSLP WHERE SlpCode = :code"
                df = self.db.get_dataframe(query, params={"code": slp_code})
                
                if not df.empty and 'SlpName' in df.columns:
                    resolved_name = df.iloc[0]['SlpName']
                    print(f"DEBUG: SlpCode {slp_code} resolvido para '{resolved_name}'")
                    return resolved_name
                else:
                    print(f"AVISO: SlpCode {slp_code} n√£o encontrado na OSLP.")
                    return str(vendor_filter) # Retorna o ID mesmo, talvez a view aceite ou falhe graciosamente
            except Exception as e:
                print(f"Erro ao resolver SlpCode: {e}")
                return str(vendor_filter)
        
        return vendor_filter

    # --- M√©todos de Neg√≥cio (Implementa√ß√£o das Tools) ---

    @staticmethod
    def _format_sku(val):
        """Padroniza SKU para ter pelo menos 4 d√≠gitos inteiros (ex: 5 -> 0005, 201.1 -> 0201.1)."""
        if val is None: return ""
        s = str(val).strip()
        if '.' in s:
            parts = s.split('.')
            return parts[0].zfill(4) + '.' + parts[1]
        else:
            return s.zfill(4)


    def get_customer_history_markdown(self, card_code: str, limit: int = 10, vendor_filter: str = None) -> str:
        """Busca hist√≥rico de pedidos (Vers√£o Chat/Markdown)."""
        try:
            vendor_filter = self._resolve_vendor_filter(vendor_filter)
            
            # üõ°Ô∏è SECURITY: Use safe parameterization instead of f-string concatenation
            params = {"card_code": card_code, "limit": limit}
            vendor_clause = ""
            
            if vendor_filter:
                vendor_clause = " AND Vendedor_Atual = :vendor_filter"
                params["vendor_filter"] = vendor_filter

            query = f"SELECT TOP (:limit) Data_Emissao, Numero_Documento, SKU, Nome_Produto, Quantidade, Valor_Liquido, Nome_Cliente FROM FAL_IA_Dados_Vendas_Televendas WHERE Codigo_Cliente = :card_code {vendor_clause} ORDER BY Data_Emissao DESC"
            df = self.db.get_dataframe(query, params=params)
            
            if df.empty: return "Nenhuma compra recente encontrada (ou cliente fora da sua carteira)."
            return df.to_markdown(index=False)
        except Exception as e: return f"Erro ao buscar hist√≥rico: {str(e)}"

    def get_customer_history(self, card_code: str, limit: int = 20) -> pd.DataFrame:
        """Busca hist√≥rico de pedidos (Vers√£o API/DataFrame)."""
        # üõ°Ô∏è SECURITY: Use safe parameterization for card_code and limit
        query = """
        SELECT TOP (:limit) 
            Data_Emissao, Numero_Documento, SKU, Nome_Produto, 
            Quantidade, Valor_Liquido, Nome_Cliente, Tipo_Documento, 
            Status_Documento, Valor_Total_Linha, 
            Preco_Unitario_Original as Valor_Unitario 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Codigo_Cliente = :card_code 
        ORDER BY Data_Emissao DESC
        """
        df = self.db.get_dataframe(query, params={"card_code": card_code, "limit": limit})
        if not df.empty and 'SKU' in df.columns:
            df['SKU'] = df['SKU'].apply(self._format_sku)
        return df

    def get_customer_details_json_string(self, card_code: str, vendor_filter: str = None) -> str:
        """Busca detalhes do cliente (Vers√£o Chat/JSON String)."""
        try:
            # Check ownership if filter is present
            vendor_filter = self._resolve_vendor_filter(vendor_filter)
            if vendor_filter:
                # Security Check: Verify if this client belongs to the vendor (has sales)
                check_query = "SELECT TOP 1 1 FROM FAL_IA_Dados_Vendas_Televendas WHERE Codigo_Cliente = :card_code AND Vendedor_Atual = :vendor"
                check_df = self.db.get_dataframe(check_query, params={"card_code": card_code, "vendor": vendor_filter})
                if check_df.empty:
                    return "Acesso Negado: Este cliente n√£o pertence √† sua carteira de vendas."

            query = "SELECT TOP 1 CardCode, CardName, Telefone, Email, Endereco, AtivoDesde FROM VW_MariIA_ClientDetails WHERE CardCode = :card_code"
            df = self.db.get_dataframe(query, params={"card_code": card_code})
            if df.empty: return "Cliente n√£o encontrado."
            return df.iloc[0].to_json()
        except Exception as e: return f"Erro ao buscar detalhes: {str(e)}"
        
    def get_customer_details(self, card_code: str) -> dict:
        """Busca detalhes do cliente (Vers√£o API/Dict)."""
        try:
            query = "SELECT TOP 1 CardCode, CardName, Telefone, Email, Endereco, AtivoDesde FROM VW_MariIA_ClientDetails WHERE CardCode = :card_code"
            df = self.db.get_dataframe(query, params={"card_code": card_code})
            if df.empty: return {}
            return df.iloc[0].to_dict()
        except: return {}

    def get_sales_trend(self, card_code: str, months: int = 6) -> dict:
        """Busca tend√™ncia de vendas para o gr√°fico (Vers√£o API)."""
        try:
            # SQL Server Query
            query = f"""
            SELECT 
                FORMAT(Data_Emissao, 'MM/yy') as Mes,
                CASE 
                    WHEN Categoria_Produto LIKE '%ARROZ%' THEN 'Arroz'
                    WHEN Categoria_Produto LIKE '%FEIJAO%' THEN 'Feij√£o'
                    WHEN Categoria_Produto LIKE '%MASSA%' THEN 'Massas'
                    ELSE 'Outros'
                END as Categoria,
                SUM(COALESCE(Valor_Liquido, Valor_Total_Linha, 0)) as Total,
                MIN(Data_Emissao) as SortDate
            FROM FAL_IA_Dados_Vendas_Televendas 
            WHERE Codigo_Cliente = :card_code 
              AND Data_Emissao >= DATEADD(month, -{months}, GETDATE())
            GROUP BY FORMAT(Data_Emissao, 'MM/yy'),
                     CASE 
                        WHEN Categoria_Produto LIKE '%ARROZ%' THEN 'Arroz'
                        WHEN Categoria_Produto LIKE '%FEIJAO%' THEN 'Feij√£o'
                        WHEN Categoria_Produto LIKE '%MASSA%' THEN 'Massas'
                        ELSE 'Outros'
                     END
            ORDER BY SortDate ASC
            """
            df = self.db.get_dataframe(query, params={"card_code": card_code})
            
            if df.empty:
                return {"labels": [], "datasets": []}

            # Garantir ordena√ß√£o correta e labels √∫nicos
            ordered_months = df.sort_values('SortDate')['Mes'].unique().tolist()
            
            categories = ['Arroz', 'Feij√£o', 'Massas']
            colors = {
                'Arroz': '#1A2F5A',
                'Feij√£o': '#22C55E',
                'Massas': '#F97316'
            }
            
            datasets = []
            for cat in categories:
                cat_data = []
                for m in ordered_months:
                    val = df[(df['Mes'] == m) & (df['Categoria'] == cat)]['Total'].sum()
                    cat_data.append(float(val))
                
                datasets.append({
                    "name": cat,
                    "data": cat_data,
                    "color": colors.get(cat)
                })
                
            return {
                "labels": ordered_months,
                "datasets": datasets
            }
        except Exception as e:
            print(f"Erro em get_sales_trend: {str(e)}")
            return {"labels": [], "datasets": []}

        """Busca vendas recentes carteira (Vers√£o Chat/Markdown)."""
        # Resolve SlpCode -> Name
        vendor_filter = self._resolve_vendor_filter(vendor_filter)

        query = f"""
        SELECT TOP 10 Nome_Cliente, Valor_Liquido, Data_Emissao 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{days}, GETDATE())
        """
        if vendor_filter:
            query += f" AND Vendedor_Atual = '{vendor_filter}'"
        
        query += " ORDER BY Valor_Liquido DESC"
        
        df = self.db.get_dataframe(query)
        if df.empty: return "Sem vendas no per√≠odo para sua carteira."
        return df.to_markdown(index=False)
        
    def run_sales_analysis_query(self, t_sql_query: str, explanation: str = "", vendor_filter: str = None) -> str:
        """Executa uma query SQL anal√≠tica criada pela IA de forma segura."""
        try:
            # 1. Valida√ß√£o de Seguran√ßa B√°sica
            forbidden_keywords = ['UPDATE', 'DELETE', 'DROP', 'INSERT', 'ALTER', 'TRUNCATE', 'EXEC', 'MERGE', 'GRANT', 'REVOKE', '--', ';']
            normalized_query = t_sql_query.upper().strip()
            
            if not normalized_query.startswith("SELECT"):
                 return "Erro: Apenas consultas SELECT s√£o permitidas."
                 
            for kw in forbidden_keywords:
                if f" {kw} " in normalized_query or normalized_query.startswith(kw): # Check words surrounded by spaces or at start
                     return f"Erro: O comando ou caracter '{kw}' n√£o √© permitido por seguran√ßa."

            # 2. Inje√ß√£o de Filtro de Vendedor (Seguran√ßa de Dados)
            vendor_filter = self._resolve_vendor_filter(vendor_filter)
            final_query = t_sql_query
            
            if vendor_filter:
                print(f"DEBUG: Security enforcement enabled for vendor: {vendor_filter}")
                # Simple parser injection
                # Finds the first WHERE or adds it after FROM ... Table
                # Robust approach: Wrap query? No, T-SQL subqueries need alias and context.
                # Regex approach to append AND
                
                # Check if WHERE exists (naively)
                if "WHERE" in normalized_query:
                    # Replace regex safe?
                    # "WHERE condition" -> "WHERE (condition) AND Vendedor_Atual = '...'"
                    # Using replace is risky if there are multiple subqueries.
                    # Best approach for this agent which queries ONE table (FAL_IA_Dados_Vendas_Televendas):
                    # Append strictly.
                    
                    # NOTE: This assumes the AI generated a valid query against the main table.
                    # If AI did "SELECT * FROM Table WHERE X GROUP BY Y", appending AND is wrong position.
                    
                    # Better Strategy:
                    # Enforce that the AI *must* include the filter? No, we can't trust it.
                    # We will WRAP it.
                    # SELECT * FROM ( <Query> ) AS SafeWrapper WHERE Vendedor_Atual = '...'
                    # BUT 'Vendedor_Atual' must be in the select list of the inner query for this to work.
                    # If AI did "SELECT SUM(x) FROM ...", Vendedor_Atual is dropped.
                    
                    # Strategy 2: Text Injection.
                    # Most queries are: SELECT ... FROM FAL_IA_Dados_Vendas_Televendas WHERE ... GROUP BY ... ORDER BY ...
                    # We inject " AND Vendedor_Atual = '...'" after "WHERE"
                    # If no WHERE, we inject " WHERE Vendedor_Atual = '...' " before GROUP BY or ORDER BY.
                    
                    # Let's try a regex replace compatible with T-SQL.
                    
                    # Pattern: FROM table [alias] [WHERE condition]
                    # We will force the AI to query *only* FAL_IA_Dados_Vendas_Televendas
                    
                    if "FAL_IA_Dados_Vendas_Televendas" not in t_sql_query:
                         return "Erro: Consulta deve ser na tabela FAL_IA_Dados_Vendas_Televendas."
                         
                    # Naive Injection
                    if "WHERE" in normalized_query:
                        final_query = re.sub(r"(?i)WHERE", f"WHERE (Vendedor_Atual = '{vendor_filter}') AND (", t_sql_query, count=1)
                        # Close parenthesis? We opened one after AND? No, wait.
                        # WHERE (filter) AND (original_conditions...)
                        # To do this safely implies knowing where original conditions end.
                        
                        # Simpler: Just prepend to the condition.
                        # WHERE X -> WHERE Vendedor_Atual='Vendor' AND (X
                        # But we need to close the paren?
                        
                        # Let's use string formatting safe injection
                        final_query = t_sql_query.replace("WHERE", f"WHERE Vendedor_Atual = '{vendor_filter}' AND ", 1)
                        # This works 99% of time if simple conditions.
                    else:
                        # Find where to insert WHERE (before GROUP BY, ORDER BY, or END)
                        # If GROUP BY exists
                        if "GROUP BY" in normalized_query:
                             final_query = t_sql_query.replace("GROUP BY", f"WHERE Vendedor_Atual = '{vendor_filter}' GROUP BY", 1)
                        elif "ORDER BY" in normalized_query:
                             final_query = t_sql_query.replace("ORDER BY", f"WHERE Vendedor_Atual = '{vendor_filter}' ORDER BY", 1)
                        else:
                             final_query += f" WHERE Vendedor_Atual = '{vendor_filter}'"
            
            # 3. Execu√ß√£o
            print(f"DEBUG: Executing AI SQL (Secured): {final_query}")
            df = self.db.get_dataframe(final_query)
            
            if df.empty:
                return "A consulta retornou zero resultados (verifique se os dados pertencem √† sua carteira)."
                
            # Limita retorno para o chat n√£o explodir
            if len(df) > 30:
                df = df.head(30)
                
            return f"**Resultado da An√°lise ({explanation}):**\n\nQuery Segura Executada.\n\n" + df.to_markdown(index=False)
            
        except Exception as e:
            return f"Erro ao executar an√°lise SQL: {str(e)}"

    def get_customer_profile_average(self, card_code: str, last_purchase_date) -> float:
        """
        Calcula a m√©dia de fardos totais por pedido nos 180 dias ANTERIORES √† √∫ltima compra.
        Usa cache manual para evitar reprocessamento constante.
        """
        # Chave composta para garantir que se a data mudar, o cache invalida
        cache_key = f"profile_{card_code}_{last_purchase_date}"
        if cache_key in self.profile_cache:
            return self.profile_cache[cache_key]

        try:
            # Garante que a data est√° em formato string ISO para o SQL se necess√°rio
            date_ref = str(last_purchase_date)
            
            query = f"""
            SELECT ROUND(AVG(CAST(SumQ.Total_Fardos_Pedido AS FLOAT)), 1) as Media_Hist
            FROM (
                SELECT Numero_Documento, SUM(Quantidade) as Total_Fardos_Pedido
                FROM FAL_IA_Dados_Vendas_Televendas
                WHERE Codigo_Cliente = :card_code
                  AND Data_Emissao >= DATEADD(day, -180, :date_ref)
                  AND Data_Emissao <= :date_ref
                GROUP BY Numero_Documento
            ) SumQ
            """
            df = self.db.get_dataframe(query, params={"card_code": card_code, "date_ref": date_ref})
            
            result = 0.0
            if not df.empty and df.iloc[0]['Media_Hist'] is not None:
                result = max(0.0, float(df.iloc[0]['Media_Hist']))
            
            # Salva no cache antes de retornar
            self.profile_cache[cache_key] = result
            # print(f"DEBUG: Profile Average for {card_code}: {result} (Date Ref: {date_ref})")
            return result
        except Exception as e:
            print(f"Erro ao calcular m√©dia de perfil para {card_code}: {e}")
            return 0.0

        """Busca vendas agregadas por cliente (Vers√£o Dashboard/DataFrame)."""
        # Resolve SlpCode -> Name
        vendor_filter = self._resolve_vendor_filter(vendor_filter)

        # Query ultra-r√°pida focada no ranking din√¢mico
        query = f"""
        SELECT 
            Codigo_Cliente,
            MAX(Nome_Cliente) as Nome_Cliente,
            MAX(Cidade) as Cidade,
            MAX(Estado) as Estado,
            SUM(Valor_Liquido) as Total_Venda,
            MAX(Data_Emissao) as Ultima_Compra
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{max_days}, GETDATE()) 
        AND Data_Emissao <= DATEADD(day, -{min_days}, GETDATE())
        """
        
        if vendor_filter:
             query += f" AND Vendedor_Atual = '{vendor_filter}'"
             
        query += " GROUP BY Codigo_Cliente ORDER BY Total_Venda DESC"
        
        df = self.db.get_dataframe(query)
        
        # Enriquecimento com M√©dia de Perfil (usando Cache)
        if not df.empty:
            df['Media_Fardos'] = df.apply(
                lambda row: self.get_customer_profile_average(row['Codigo_Cliente'], row['Ultima_Compra']), 
                axis=1
            )
            
        return df

    def get_bales_breakdown(self, card_code: str, days: int = 180) -> pd.DataFrame:
        """Busca a m√©dia de fardos por SKU para um cliente espec√≠fico."""
        query = f"""
        SELECT 
            SKU,
            MAX(Nome_Produto) as Produto,
            ROUND(AVG(Quantidade), 1) as Media_SKU,
            COUNT(Numero_Documento) as Vezes_Comprado
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Codigo_Cliente = :card_code 
          AND Data_Emissao >= DATEADD(day, -{days}, GETDATE())
        GROUP BY SKU
        ORDER BY Media_SKU DESC
        """

        df = self.db.get_dataframe(query, params={"card_code": card_code})
        if not df.empty and 'SKU' in df.columns:
            df['SKU'] = df['SKU'].apply(self._format_sku)
        return df

    def get_inactive_customers_markdown(self, days_without_purchase: int = 30, vendor_filter: str = None) -> str:
        """Clientes inativos (Vers√£o Chat/Markdown)."""
        vendor_filter = self._resolve_vendor_filter(vendor_filter)
        vendor_clause = f" AND Vendedor_Atual = '{vendor_filter}'" if vendor_filter else ""
        query = f"""
        SELECT TOP 15 Codigo_Cliente, MAX(Nome_Cliente) as Nome, MAX(Data_Emissao) as Ultima_Compra 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE 1=1 {vendor_clause}
        GROUP BY Codigo_Cliente 
        HAVING MAX(Data_Emissao) < DATEADD(day, -{days_without_purchase}, GETDATE()) 
        ORDER BY Ultima_Compra DESC
        """
        df = self.db.get_dataframe(query)
        if df.empty: return "Nenhum cliente inativo relevante encontrado na sua carteira."
        return df.to_markdown(index=False)

    def get_sales_insights(self, min_days: int = 0, max_days: int = 30, vendor_filter: str = None) -> pd.DataFrame:
        """
        Busca insights de vendas (clientes positivados/ativos) no per√≠odo.
        Retorna lista de clientes com total de vendas e √∫ltima compra no range.
        """
        # Filtro de vendedor
        vendor_filter = self._resolve_vendor_filter(vendor_filter)
        vendor_clause = f" AND Vendedor_Atual = '{vendor_filter}'" if vendor_filter else ""
        
        # Ajuste para garantir que min < max
        if min_days > max_days:
            min_days, max_days = max_days, min_days

        # Query simplificada sem CTE para melhor performance
        query = f"""
        SELECT 
            Codigo_Cliente,
            MAX(Nome_Cliente) as Nome_Cliente,
            MAX(Cidade) as Cidade,
            MAX(Estado) as Estado,
            MAX(Data_Emissao) as Ultima_Compra,
            SUM(Valor_Total_Linha) as Total_Venda,
            -- M√©dia de Volume por Pedido (Media Fardos)
            CASE 
                WHEN COUNT(DISTINCT Numero_Documento) > 0 
                THEN CAST(SUM(Quantidade) AS FLOAT) / COUNT(DISTINCT Numero_Documento)
                ELSE 0 
            END as Media_Fardos
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{max_days}, GETDATE())
          AND Data_Emissao <= DATEADD(day, -{min_days}, GETDATE())
          {vendor_clause}
        GROUP BY Codigo_Cliente
        ORDER BY Total_Venda DESC
        """
        
        df = self.db.get_dataframe(query)
        
        # REMOVIDO: Enriquecimento com M√©dia de Perfil para evitar timeout
        # O c√°lculo de Media_Fardos fazia N queries adicionais (uma por cliente)
        # causando lentid√£o extrema. Pode ser calculado sob demanda se necess√°rio.
        # if not df.empty:
        #     df['Media_Fardos'] = df.apply(
        #         lambda row: self.get_customer_profile_average(row['Codigo_Cliente'], row['Ultima_Compra']), 
        #         axis=1
        #     )
            
        return df

    def get_inactive_customers(self, min_days: int = 30, max_days: int = 365, vendor_filter: str = None) -> pd.DataFrame:
        """Busca clientes inativos (sem compras no per√≠odo) para o dashboard.
           Ordena√ß√£o: Maior M√©dia de Fardos e Valor.
        """
        
        # Filtro de vendedor
        vendor_filter = self._resolve_vendor_filter(vendor_filter)
        vendor_clause = f" AND Vendedor_Atual = '{vendor_filter}'" if vendor_filter else ""
        
        query = f"""
        WITH Base_Inativos AS (
            SELECT 
                Codigo_Cliente,
                MAX(Nome_Cliente) as Nome_Cliente,
                MAX(Cidade) as Cidade,
                MAX(Estado) as Estado,
                MAX(Data_Emissao) as Ultima_Compra,
                -- Valor total hist√≥rico (ou no per√≠odo anal√≠tico dispon√≠vel na view)
                SUM(Valor_Total_Linha) as Valor_Total_Historico
            FROM FAL_IA_Dados_Vendas_Televendas 
            WHERE 1=1 {vendor_clause}
            GROUP BY Codigo_Cliente
            HAVING MAX(Data_Emissao) < DATEADD(day, -{min_days}, GETDATE())
               AND MAX(Data_Emissao) >= DATEADD(day, -{max_days}, GETDATE())
        )
        SELECT * FROM Base_Inativos
        """
        
        df = self.db.get_dataframe(query)
        
        if not df.empty:
            # Calcular Media_Fardos (idealmente seria no SQL, mas mantendo l√≥gica existente por compatibilidade)
            # Para evitar N queries se houver muitos, idealmente cache ajuda.
            # Se for muito lento, considerar mover logica para SQL.
            df['Media_Fardos'] = df.apply(
                lambda row: self.get_customer_profile_average(row['Codigo_Cliente'], row['Ultima_Compra']), 
                axis=1
            )
            
            # Ordena√ß√£o solicitada: Maior Media de Fardos e Valor
            df = df.sort_values(by=['Media_Fardos', 'Valor_Total_Historico'], ascending=[False, False])
        else:
            # Garante colunas mesmo vazio
            df['Media_Fardos'] = 0.0
            
        return df

    def get_top_products(self, days: int = 90, vendor_filter: str = None) -> str:
        vendor_filter = self._resolve_vendor_filter(vendor_filter)
        query = f"""
        SELECT TOP 20 SKU, MAX(Nome_Produto) as Produto, SUM(Valor_Liquido) as Total 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{days}, GETDATE())
        """
        if vendor_filter:
            query += f" AND Vendedor_Atual = '{vendor_filter}'"
            
        query += " GROUP BY SKU ORDER BY Total DESC"
        df = self.db.get_dataframe(query)
        if not df.empty and 'SKU' in df.columns:
            df['SKU'] = df['SKU'].apply(self._format_sku)
        return df.to_markdown(index=False)

    def get_company_kpis(self, days: int = 30) -> str:
        query = f"""
        SELECT 
            SUM(Valor_Liquido) as Faturamento, 
            COUNT(DISTINCT Numero_Documento) as Pedidos 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{days}, GETDATE())
        """
        df = self.db.get_dataframe(query)
        return df.iloc[0].to_json()

    def get_top_sellers(self, days: int = 30) -> str:
        query = f"""
        SELECT TOP 5 Vendedor_Atual, SUM(Valor_Liquido) as Total 
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, -{days}, GETDATE()) 
        GROUP BY Vendedor_Atual ORDER BY Total DESC
        """
        df = self.db.get_dataframe(query)
        return df.to_markdown(index=False)

    def get_volume_insights(self, days: int = 90) -> str:
        """
        Retorna produtos de alto volume com m√©tricas quantitativas.
        Usa f-strings internamente com os dias (seguro pois √© int interno) 
        mas a l√≥gica de colunas e filtros √© est√°tica.
        """
        query = f"""
        SELECT TOP 15 
            SKU,
            MAX(Nome_Produto) as Produto,
            SUM(Quantidade) as Volume_Total,
            COUNT(DISTINCT Codigo_Cliente) as Clientes_Ativos,
            ROUND(AVG(Valor_Liquido), 2) as Ticket_Medio,
            MAX(Categoria_Produto) as Categoria
        FROM FAL_IA_Dados_Vendas_Televendas 
        WHERE Data_Emissao >= DATEADD(day, :days, GETDATE())
        GROUP BY SKU
        HAVING SUM(Quantidade) > 3000
        ORDER BY Volume_Total DESC
        """
        df = self.db.get_dataframe(query, params={"days": -days})
        if not df.empty and 'SKU' in df.columns:
            df['SKU'] = df['SKU'].apply(self._format_sku)
        
        if df.empty:
            return "Nenhum dado de volume significativo encontrado no per√≠odo."
            
        return df.to_markdown(index=False)
    
    def get_portfolio_analysis(self, vendor_filter: str = None, period_days: int = 30) -> dict:
        """
        Analisa a carteira completa do vendedor.
        
        Retorna:
        - Total de clientes √∫nicos
        - Clientes positivados (com vendas no per√≠odo)
        - Clientes n√£o positivados (sem vendas no per√≠odo)
        - Taxa de positiva√ß√£o
        - Lista completa de clientes
        """
        vendor_filter = self._resolve_vendor_filter(vendor_filter)
        vendor_clause = f"AND Vendedor_Atual = '{vendor_filter}'" if vendor_filter else ""
        
        # Query para an√°lise da carteira
        query = f"""
        WITH Carteira_Completa AS (
            SELECT DISTINCT 
                Codigo_Cliente,
                MAX(Nome_Cliente) as Nome_Cliente,
                MAX(Cidade) as Cidade,
                MAX(Estado) as Estado
            FROM FAL_IA_Dados_Vendas_Televendas
            WHERE 1=1 {vendor_clause}
            GROUP BY Codigo_Cliente
        ),
        Vendas_Periodo AS (
            SELECT 
                Codigo_Cliente,
                SUM(Valor_Liquido) as Total_Vendas,
                MAX(Data_Emissao) as Ultima_Compra,
                DATEDIFF(day, MAX(Data_Emissao), GETDATE()) as Dias_Desde_Compra
            FROM FAL_IA_Dados_Vendas_Televendas
            WHERE Data_Emissao >= DATEADD(day, -{period_days}, GETDATE())
                  {vendor_clause}
            GROUP BY Codigo_Cliente
        )
        SELECT 
            c.Codigo_Cliente,
            c.Nome_Cliente,
            c.Cidade,
            c.Estado,
            CASE WHEN v.Codigo_Cliente IS NOT NULL THEN 1 ELSE 0 END as Positivado,
            ISNULL(v.Total_Vendas, 0) as Total_Vendas,
            v.Ultima_Compra,
            v.Dias_Desde_Compra,
            ISNULL(m.Media_Fardos, 0) as Media_Fardos
        FROM Carteira_Completa c
        LEFT JOIN Vendas_Periodo v ON c.Codigo_Cliente = v.Codigo_Cliente
        OUTER APPLY (
            SELECT TOP 1 
                AVG(CAST(sub.Qtd_Total AS DECIMAL(10,2))) as Media_Fardos
            FROM (
                SELECT 
                    Data_Emissao, 
                    SUM(Quantidade) as Qtd_Total
                FROM FAL_IA_Dados_Vendas_Televendas v_inner
                WHERE v_inner.Codigo_Cliente = c.Codigo_Cliente
                  AND v_inner.Data_Emissao >= DATEADD(month, -6, GETDATE()) -- M√©dia dos √∫ltimos 6 meses
                GROUP BY Data_Emissao
            ) sub
        ) m
        ORDER BY Positivado DESC, Total_Vendas DESC
        """
        
        df = self.db.get_dataframe(query)
        
        if df.empty:
            return {
                "summary": {
                    "total_clients": 0,
                    "positivated_clients": 0,
                    "non_positivated_clients": 0,
                    "positivation_rate": 0.0
                },
                "clients": []
            }
        
        # Calcular m√©tricas
        total = len(df)
        positivated = df[df['Positivado'] == 1].shape[0]
        non_positivated = total - positivated
        rate = (positivated / total * 100) if total > 0 else 0
        
        # Formatar clientes
        clients = []
        for _, row in df.iterrows():
            clients.append({
                "card_code": row['Codigo_Cliente'],
                "name": row['Nome_Cliente'],
                "city": row['Cidade'],
                "state": row['Estado'],
                "is_positivated": bool(row['Positivado']),
                "total_sales": float(row['Total_Vendas']),
                "last_purchase": row['Ultima_Compra'].isoformat() if pd.notna(row['Ultima_Compra']) else None,
                "days_since_purchase": int(row['Dias_Desde_Compra']) if pd.notna(row['Dias_Desde_Compra']) else None
            })
        
        return {
            "summary": {
                "total_clients": total,
                "positivated_clients": positivated,
                "non_positivated_clients": non_positivated,
                "positivation_rate": round(rate, 1)
            },
            "clients": clients
        }
    
    
    # --- Chat Stream ---

    async def chat_stream(self, user_message: str, history: list = [], vendor_filter: str = None) -> AsyncGenerator[str, None]:
        """
        Gera resposta em stream, lidando automaticamente com chamadas de fun√ß√£o.
        """
        if not self.model:
            yield "O modelo de IA n√£o est√° dispon√≠vel."
            return

        chat = self.model.start_chat() 
        # Nota: Vertex AI SDK gerencia o hist√≥rico na sess√£o 'chat', mas como recebemos history do frontend (stateless), 
        # idealmente dever√≠amos reconstruir o history do chat object. 
        # Para simplificar e performar, enviaremos o history como contexto na mensagem ou reconstruiremos.
        # Reconstruindo hist√≥rico b√°sico:
        
        history_instruction = []
        if history:
            for msg in history[-6:]: # Limit history
                role = "user" if msg.get('sender') == 'user' else "model"
                part = Part.from_text(msg.get('text'))
                history_instruction.append(Content(role=role, parts=[part]))
        
        chat = self.model.start_chat(history=history_instruction)

        # Envia instru√ß√£o de sistema din√¢mica para o vendedor atual
        resolved_vendor = self._resolve_vendor_filter(vendor_filter)
        vendor_context = f"\n\nCONTEXTO DO USU√ÅRIO:\nVoc√™ est√° conversando com: {resolved_vendor or 'Vendedor'}.\nLembre-se: Use as ferramentas de busca e elas automaticamente filtrar√£o os dados para a sua carteira, se necess√°rio."
        
        # Envia mensagem inicial
        response_stream = await chat.send_message_async(user_message + vendor_context, stream=True)
        
        # Itera sobre chunks. O SDK cuida da execu√ß√£o autom√°tica de tools? 
        # R: N√£o automaticamente no modo stream async simples sem orquestra√ß√£o. 
        # Precisamos detectar o FunctionCall, executar e devolver o FunctionResponse.
        
        # OBSERVA√á√ÉO CR√çTICA SOBRE VERTEX AI PYTHON SDK + STREAM + TOOLS:
        # A implementa√ß√£o padr√£o de `send_message_async(stream=True)` retorna chunks.
        # Se a IA decidir chamar uma func, o primeiro chunk conter√° `function_call`.
        # Precisamos checar isso.
        
        # Para simplificar neste primeiro passo de otimiza√ß√£o, devido √† complexidade de loop manual de function calling com stream,
        # vamos usar uma abordagem h√≠brida ou a Feature "Automatic Function Calling" se dispon√≠vel na vers√£o da lib.
        # Assumindo loop manual padr√£o:
        
        collected_chunks = []
        function_call_detected = None
        
        try:
            async for chunk in response_stream:
                try:
                    # Inspe√ß√£o manual profunda para evitar erros de propriedade do SDK
                    # Acessar propriedades de 'chunk' que n√£o existem pode gerar erro, ent√£o protegemos tudo
                    
                    found_fn = False
                    if hasattr(chunk, 'candidates') and chunk.candidates:
                        for candidate in chunk.candidates:
                            if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                                for part in candidate.content.parts:
                                    # Verifica se tem function_call (pode ser m√©todo ou propriedade dependendo do SDK)
                                    # Tentamos acesso seguro
                                    fn = getattr(part, 'function_call', None)
                                    if fn:
                                        function_call_detected = fn
                                        found_fn = True
                                        break
                            if found_fn: break
                    
                    if found_fn or function_call_detected:
                        break # Sai do loop de stream
                    
                    # Extra√ß√£o Manual de Texto (Evita chunk.text que lan√ßa ValueError)
                    extracted_text = ""
                    if hasattr(chunk, 'candidates') and chunk.candidates:
                         for candidate in chunk.candidates:
                             if hasattr(candidate, 'content') and hasattr(candidate.content, 'parts'):
                                 for part in candidate.content.parts:
                                     # Tenta pegar texto de forma segura
                                     pt = getattr(part, 'text', "")
                                     if pt: extracted_text += pt
                    
                    if extracted_text:
                        yield extracted_text
                        
                except Exception as inner_e:
                    # Loga mas n√£o quebra o stream
                    # print(f"DEBUG: Erro ao processar chunk individual: {inner_e}")
                    continue
                    
        except Exception as stream_e:
            print(f"DEBUG: Erro fatal no stream (possivel function call malformada): {stream_e}")
            yield f"\n\n[Sistema] Erro no processamento inicial: {str(stream_e)}"
                
        if function_call_detected:
            # Executa a tool
            func_name = function_call_detected.name
            func_args = function_call_detected.args
            
            print(f"DEBUG: Tool Call Detectada: {func_name} Args: {func_args}")
            
            # Keep-alive notification for user
            yield f"\n\n_Consultando dados para {func_name}..._\n\n"
            
            tool_result = "Erro na execu√ß√£o da ferramenta."
            
            # Mapeamento din√¢mico
            if hasattr(self, func_name):
                method = getattr(self, func_name)
                # Converte args (proto map) para dict python
                kwargs = {k: v for k, v in func_args.items()}
                
                # Injeta vendor_filter se o m√©todo aceitar
                import inspect
                sig = inspect.signature(method)
                if 'vendor_filter' in sig.parameters:
                    kwargs['vendor_filter'] = vendor_filter
                    
                try:
                    tool_result = method(**kwargs)
                except Exception as e:
                    tool_result = f"Erro ao executar {func_name}: {e}"
            
            print(f"DEBUG: Tool Result size: {len(str(tool_result))}")
            
            # Envia resposta da tool de volta para o modelo gerar a resposta final (agora sim com stream de texto)
            
            part_func_response = Part.from_function_response(
                name=func_name,
                response={"content": tool_result}
            )

            # Continua a conversa com o resultado da fun√ß√£o
            try:
                # WORKAROUND: Stream ap√≥s Tool Calling pode ser inst√°vel no Vertex AI SDK.
                # Mudamos para stream=False (resposta completa) para garantir que o texto chegue.
                final_response = await chat.send_message_async(
                    [part_func_response],
                    stream=False
                )
                
                # Debug response details - RESTORED
                print(f"DEBUG: Final Response Object: {final_response}")
                if hasattr(final_response, 'candidates') and final_response.candidates:
                     print(f"DEBUG: Finish Reason: {final_response.candidates[0].finish_reason}")
                     if hasattr(final_response.candidates[0], 'safety_ratings'):
                         print(f"DEBUG: Safety Ratings: {final_response.candidates[0].safety_ratings}")

                # Verifica√ß√£o segura do texto final
                final_text = ""
                try:
                    if hasattr(final_response, 'text') and final_response.text:
                        final_text = final_response.text
                except Exception:
                    # Fallback manual se .text falhar
                     if hasattr(final_response, 'candidates') and final_response.candidates:
                         for cand in final_response.candidates:
                             for part in cand.content.parts:
                                 if hasattr(part, 'text') and part.text:
                                     final_text += part.text

                if final_text:
                    yield final_text
                else:
                    # Fallback Inteligente: Tenta formatar o JSON em Markdown se o model falhar
                    formatted_fallback = ""
                    try:
                        import json
                        data = json.loads(tool_result)
                        if isinstance(data, dict):
                            formatted_fallback += "### Dados Encontrados:\n"
                            for k, v in data.items():
                                formatted_fallback += f"- **{k}:** {v}\n"
                        elif isinstance(data, list):
                            formatted_fallback += "### Dados Encontrados:\n"
                            # Se for lista, pega o primeiro ou faz tabela simples
                            if len(data) > 0 and isinstance(data[0], dict):
                                keys = data[0].keys()
                                header = "| " + " | ".join(keys) + " |"
                                divider = "| " + " | ".join(["---"] * len(keys)) + " |"
                                rows = ""
                                for item in data[:5]: # Limita a 5 para n√£o poluir
                                    rows += "| " + " | ".join([str(item.get(k, '')) for k in keys]) + " |\n"
                                formatted_fallback = f"{header}\n{divider}\n{rows}"
                            else:
                                formatted_fallback += str(data)
                        else:
                             formatted_fallback = tool_result
                    except:
                        formatted_fallback = tool_result
                    
                    yield f"\n\n{formatted_fallback}\n\n"

            except Exception as e:
                # Se falhar aqui, n√£o tem muito o que fazer, mas n√£o crasheamos o stream
                print(f"DEBUG: Erro no stream p√≥s-tool: {e}")
                yield f"\n\n[Sistema] Erro ao gerar resposta final: {str(e)}"
    
    # Manter m√©todo legado para evitar quebrar endpoints antigos por enquanto (se necess√°rio) ou redirecionar
    async def chat(self, user_message: str, history: list = [], vendor_filter: str = None) -> str:
        """Vers√£o n√£o-stream (legado/compatibilidade)."""
        full_response = ""
        async for chunk in self.chat_stream(user_message, history, vendor_filter):
            full_response += chunk
        return full_response

    # Legacy Stubs - Manter para n√£o quebrar API.py que chama m√©todos diretamente (ex: /insights)
    # Mas agora eles s√£o chamados internamente pelas tools.
    # O ideal √© refatorar o api.py para usar m√©todos de business, mas a estrutura da classe unificou isso.
    # Os m√©todos business est√£o definidos acima (get_customer_history, etc).
    
    # generate_pitch precisa ser mantido pois √© um fluxo espec√≠fico
    async def generate_pitch(self, card_code: str, target_sku: str = "", vendor_filter: str = None) -> dict:
        """Gera um pitch de vendas estruturado (Vers√£o API)."""
        # Resolve Filter (para uso futuro se precisar filtrar contexto)
        vendor_filter = self._resolve_vendor_filter(vendor_filter) # Apenas resolve, mas pitch usa card_code
        
        # 1. Recupera dados de contexto
        details = self.get_customer_details(card_code)
        hist = self.get_customer_history(card_code, limit=20)
        top_selling = self.get_top_products(days=90) # Top produtos gerais como sugest√£o
        volume_insights = self.get_volume_insights(days=90) # Nova ferramenta de Pulveriza√ß√£o
        
        customer_name = details.get('CardName', card_code)
        
        # 2. Constr√≥i o Prompt Robusto
        prompt = f"""
        Voc√™ √© a MARI IA, a assistente de intelig√™ncia de vendas da Fant√°stico Alimentos.
        Seu objetivo √© gerar um PITCH DE VENDAS e um PEDIDO IDEAL para o vendedor abordar o cliente {customer_name} ({card_code}).

        DADOS DO CLIENTE:
        - Nome: {customer_name}
        - Ativo Desde: {details.get('AtivoDesde', 'N/A')}
        
        HIST√ìRICO RECENTE DE COMPRAS:
        {hist.to_markdown(index=False) if not hist.empty else "Nenhuma compra recente encontrada."}

        PRODUTOS MAIS VENDIDOS DA EMPRESA (OPORTUNIDADES DE MIX):
        {top_selling}

        INSIGHTS DE VOLUME (√öLTIMOS 90 DIAS):
        {volume_insights}

        TAREFAS E REGRAS DE NEG√ìCIO:
        1. **Perfil de Compra**: Resuma o que o cliente compra (ex: Foco em Arroz, itens de cesta b√°sica).
        2. **Frequ√™ncia**: Avalie a recorr√™ncia e dias desde o √∫ltimo pedido faturado.
        3. **Pitch de Venda**: Crie uma abordagem curta (2-3 frases), matadora e persuasiva focada em DIVERSIFICA√á√ÉO e VOLUME. Use os dados de volume para dar autoridade.
        4. **Pedido Ideal (ESTRAT√âGIA DE PULVERIZA√á√ÉO - PRIORIDADE M√ÅXIMA)**: 
           Sugira 3 a 5 SKUs seguindo esta HIERARQUIA OBRIGAT√ìRIA:
           
           a) **1 Item √Çncora** (20-30% da quantidade): O SKU recorrente principal do cliente (giro garantido).
           
           b) **2-3 Itens de Pulveriza√ß√£o** (50-60% da quantidade - FOCO PRINCIPAL):
              - Selecione produtos dos INSIGHTS DE VOLUME que o cliente N√ÉO comprou nos √∫ltimos 60 dias
              - PRIORIZE itens com maior Volume_Total da lista
              - DIVERSIFIQUE categorias (se compra Arroz, sugira Feij√£o + Massas + √ìleo)
              - Foque em produtos com alta rotatividade e giro r√°pido garantido
           
           c) **1 Item Estrat√©gico** (10-20% - Opcional):
              - Produto premium, lan√ßamento ou margem superior
              - Justifique o valor agregado (Ex: Margem ou Inova√ß√£o)
           
           REGRA CR√çTICA: Pelo menos 60% da QUANTIDADE TOTAL deve vir de SKUs de categorias 
           DIFERENTES das recorrentes do cliente. Priorize PULVERIZA√á√ÉO com VOLUME.
        
        5. **Transpar√™ncia (REGRAS ESTRITAS)**: Voc√™ DEVE retornar exatamente 3 motivos na lista `reasons`, com os seguintes t√≠tulos e √≠cones:
           - T√≠tulo: "Timing Ideal" | √çcone: "history" | Conte√∫do: An√°lise de dias desde a √∫ltima compra e risco de ruptura.
           - T√≠tulo: "Giro Garantido" | √çcone: "star" | Conte√∫do: SKU recorrente do cliente que n√£o pode faltar (item √¢ncora).
           - T√≠tulo: "Oportunidade de Mix" | √çcone: "trending_up" | Conte√∫do: Explicar QUANTITATIVAMENTE o VOLUME de vendas dos produtos de pulveriza√ß√£o sugeridos usando os dados dos INSIGHTS DE VOLUME (ex: "Sugerimos X pois vendeu Y unidades nos √∫ltimos 90 dias com penetra√ß√£o em Z clientes. Diversificar seu mix reduz risco de concentra√ß√£o").
        6. **Motiva√ß√£o**: Uma frase curta no campo `motivation` que resuma a estrat√©gia de PULVERIZA√á√ÉO (ex: "Mix estrat√©gico: 1 √¢ncora + 4 produtos de alto volume").

        REGRAS DO JSON:
        - "suggested_order": [ {{"product_name": "...", "sku": "...", "quantity": 10}} ]
        - "reasons": [ {{"title": "Timing Ideal", "text": "...", "icon": "history"}}, ... ]
        - "motivation": "Frase de impacto"

        RESPONDA EXATAMENTE NESTE FORMATO JSON:
        {{
            "pitch_text": "...",
            "profile_summary": "...",
            "frequency_assessment": "...",
            "suggested_order": [...],
            "motivation": "...",
            "reasons": [
                {{"title": "Timing Ideal", "text": "...", "icon": "history"}},
                {{"title": "Giro Garantido", "text": "...", "icon": "star"}},
                {{"title": "Oportunidade", "text": "...", "icon": "trending_up"}}
            ]
        }}
        """
        
        try:
            response = await self.model.generate_content_async(
                prompt, 
                generation_config={"response_mime_type": "application/json"}
            )
            data = json.loads(response.text)
            
            # Valida√ß√£o b√°sica de campos obrigat√≥rios
            for field in ["suggested_order", "reasons"]:
                if field not in data or not isinstance(data[field], list):
                    data[field] = []
            
            return data
        except Exception as e:
            print(f"Erro em generate_pitch: {e}")
            return {
                "pitch_text": "Ol√°! Notei que faz um tempo que n√£o repomos o estoque de Arroz e Feij√£o Fant√°stico. Que tal aproveitar o pedido hoje?",
                "profile_summary": "Cliente recorrente de produtos b√°sicos.",
                "frequency_assessment": "Frequ√™ncia regular observada.",
                "suggested_order": [],
                "reasons": []
            }

if __name__ == "__main__":
    # Teste r√°pido
    import asyncio
    async def main():
        agent = TelesalesAgent()
        print("\n--- Teste Chat Stream ---")
        async for chunk in agent.chat_stream("Quem s√£o meus melhores clientes?"):
            print(chunk, end="", flush=True)
        print("\n")
        
    asyncio.run(main())
